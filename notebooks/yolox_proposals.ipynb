{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmtrack.apis import init_model\n",
    "from mmcv import VideoReader\n",
    "from mmengine.dataset import Compose, default_collate\n",
    "import numpy as np\n",
    "\n",
    "from mmtrack.utils import register_all_modules\n",
    "register_all_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/20 15:27:58 - mmengine - INFO - load model from: https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_x_8x8_300e_coco/yolox_x_8x8_300e_coco_20211126_140254-1ef88d67.pth\n",
      "03/20 15:27:58 - mmengine - INFO - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_x_8x8_300e_coco/yolox_x_8x8_300e_coco_20211126_140254-1ef88d67.pth\n",
      "03/20 15:27:59 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.multi_level_conv_cls.0.weight: copying a param with shape torch.Size([80, 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 320, 1, 1]).\n",
      "size mismatch for bbox_head.multi_level_conv_cls.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "size mismatch for bbox_head.multi_level_conv_cls.1.weight: copying a param with shape torch.Size([80, 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 320, 1, 1]).\n",
      "size mismatch for bbox_head.multi_level_conv_cls.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n",
      "size mismatch for bbox_head.multi_level_conv_cls.2.weight: copying a param with shape torch.Size([80, 320, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 320, 1, 1]).\n",
      "size mismatch for bbox_head.multi_level_conv_cls.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Workspace/mot-mmtrack/mmtrack/apis/inference.py:90: UserWarning: dataset_meta or class names are missed, use None by default.\n",
      "  warnings.warn('dataset_meta or class names are missed, '\n"
     ]
    }
   ],
   "source": [
    "model = init_model('../configs/mot/qdtrack/qdtrack_yolox_x.py', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def prepare_data(imgs):\n",
    "\n",
    "    test_pipeline = Compose(model.cfg.test_pipeline[2:])\n",
    "    data_samples = []\n",
    "    for frame_id, img in zip(range(len(imgs)), imgs):\n",
    "        data = dict(\n",
    "            img=img.astype(np.float32),\n",
    "            frame_id=frame_id,\n",
    "            ori_shape=img.shape[:2])\n",
    "        data = test_pipeline(data)\n",
    "        data_samples.append(data)\n",
    "    data_samples = default_collate(data_samples)\n",
    "\n",
    "    return data_samples\n",
    "\n",
    "def draw_boxes(boxes, image):\n",
    "    for i, box in enumerate(boxes):\n",
    "        color = (0, 0, 0)\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(box[0]), int(box[1])),\n",
    "            (int(box[2]), int(box[3])),\n",
    "            color, 1\n",
    "        )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = VideoReader('../demo/test1.mp4')\n",
    "data = prepare_data([imgs[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 640, 1152])\n"
     ]
    }
   ],
   "source": [
    "print(data['inputs']['img'].shape)\n",
    "img = data['inputs']['img'][:, 0]\n",
    "fm = model.detector.extract_feat(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.detector.train_cfg['score_thr'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, proposals = model.detector.bbox_head.loss_and_predict(\n",
    "    fm, data['data_samples'], model.detector.train_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15120, 4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals[0].bboxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois = proposals[0].bboxes[:1000]\n",
    "scores = proposals[0].scores[:1000]\n",
    "rois = rois[scores > 0.01]\n",
    "\n",
    "scaled_img = data['inputs']['img'].detach().cpu().squeeze().moveaxis(0, -1).int().numpy()\n",
    "im = draw_boxes(rois, scaled_img)\n",
    "cv2.imwrite('yolox_proposals.png', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/20 15:28:10 - mmengine - INFO - load model from: open-mmlab://detectron2/resnet50_caffe\n",
      "03/20 15:28:10 - mmengine - INFO - Loads checkpoint by openmmlab backend from path: open-mmlab://detectron2/resnet50_caffe\n",
      "03/20 15:28:11 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: conv1.bias\n",
      "\n",
      "03/20 15:28:11 - mmengine - INFO - load model from: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n",
      "03/20 15:28:11 - mmengine - INFO - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Workspace/mot-mmtrack/mmtrack/apis/inference.py:90: UserWarning: dataset_meta or class names are missed, use None by default.\n",
      "  warnings.warn('dataset_meta or class names are missed, '\n"
     ]
    }
   ],
   "source": [
    "frcnn = init_model('../configs/mot/qdtrack/qdtrack_faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval.py', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcnn_fm = frcnn.detector.extract_feat(img)\n",
    "frcnn_proposals = frcnn.detector.rpn_head.predict(\n",
    "    frcnn_fm, data['data_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_img = data['inputs']['img'].detach().cpu().squeeze().moveaxis(0, -1).int().numpy()\n",
    "im = draw_boxes(frcnn_proposals[0].bboxes[:100], scaled_img)\n",
    "cv2.imwrite('frcnn_proposals.png', im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mot-mmtrack-1x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
