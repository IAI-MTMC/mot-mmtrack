{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ckpt = torch.load(\"../../../checkpoints/res50_coco_256x192-ec54d7f3_20200709.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mmpose_version': '0.1.0+96649df',\n",
       " 'config': \"log_level = 'INFO'\\nload_from = None\\nresume_from = None\\ndist_params = dict(backend='nccl')\\nworkflow = [('train', 1)]\\ncheckpoint_config = dict(interval=10)\\nevaluation = dict(interval=8, metric='mAP')\\noptimizer = dict(type='Adam', lr=0.0005)\\noptimizer_config = dict(grad_clip=None)\\nlr_config = dict(\\n    policy='step',\\n    warmup='linear',\\n    warmup_iters=500,\\n    warmup_ratio=0.001,\\n    step=[170, 200])\\ntotal_epochs = 210\\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\\nchannel_cfg = dict(\\n    num_output_channels=17,\\n    dataset_joints=17,\\n    dataset_channel=[[\\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n    ]],\\n    inference_channel=[\\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n    ])\\nmodel = dict(\\n    type='TopDown',\\n    pretrained='models/pytorch/imagenet/resnet50-19c8e357.pth',\\n    backbone=dict(type='ResNet', depth=50),\\n    keypoint_head=dict(type='SimpleHead', in_channels=2048, out_channels=17),\\n    train_cfg=dict(),\\n    test_cfg=dict(\\n        flip_test=True,\\n        post_process=True,\\n        shift_heatmap=True,\\n        unbiased_decoding=False,\\n        modulate_kernel=11),\\n    loss_pose=dict(type='JointsMSELoss', use_target_weight=True))\\ndata_cfg = dict(\\n    image_size=[192, 256],\\n    heatmap_size=[48, 64],\\n    num_output_channels=17,\\n    num_joints=17,\\n    dataset_channel=[[\\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n    ]],\\n    inference_channel=[\\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n    ],\\n    soft_nms=False,\\n    nms_thr=1.0,\\n    oks_thr=0.9,\\n    vis_thr=0.2,\\n    bbox_thr=1.0,\\n    use_gt_bbox=True,\\n    image_thr=0.0,\\n    bbox_file=\\n    'pretrained_models/det/COCO_val2017_detections_AP_H_56_person.json')\\ntrain_pipeline = [\\n    dict(type='LoadImageFromFile'),\\n    dict(type='RandomFlip', flip_prob=0.5),\\n    dict(type='HalfBodyTransform', num_joints_half_body=8, prob_half_body=0.3),\\n    dict(type='RandomScaleRotation', rot_factor=40, scale_factor=0.5),\\n    dict(type='AffineTransform'),\\n    dict(type='ToTensor'),\\n    dict(\\n        type='NormalizeTensor',\\n        mean=[0.485, 0.456, 0.406],\\n        std=[0.229, 0.224, 0.225]),\\n    dict(type='GenerateTarget', sigma=2),\\n    dict(\\n        type='Collect',\\n        keys=['img', 'target', 'target_weight'],\\n        meta_keys=[\\n            'image_file', 'joints_3d', 'joints_3d_visible', 'center', 'scale',\\n            'rotation', 'bbox_score', 'flip_pairs'\\n        ])\\n]\\nvalid_pipeline = [\\n    dict(type='LoadImageFromFile'),\\n    dict(type='AffineTransform'),\\n    dict(type='ToTensor'),\\n    dict(\\n        type='NormalizeTensor',\\n        mean=[0.485, 0.456, 0.406],\\n        std=[0.229, 0.224, 0.225]),\\n    dict(\\n        type='Collect',\\n        keys=['img'],\\n        meta_keys=[\\n            'image_file', 'center', 'scale', 'rotation', 'bbox_score',\\n            'flip_pairs'\\n        ])\\n]\\ndata_root = 'data/coco'\\ndata = dict(\\n    samples_per_gpu=64,\\n    workers_per_gpu=2,\\n    train=dict(\\n        type='TopDownCocoDataset',\\n        ann_file='data/coco/annotations/person_keypoints_train2017.json',\\n        img_prefix='data/coco/train2017/',\\n        data_cfg=dict(\\n            image_size=[192, 256],\\n            heatmap_size=[48, 64],\\n            num_output_channels=17,\\n            num_joints=17,\\n            dataset_channel=[[\\n                0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n            ]],\\n            inference_channel=[\\n                0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n            ],\\n            soft_nms=False,\\n            nms_thr=1.0,\\n            oks_thr=0.9,\\n            vis_thr=0.2,\\n            bbox_thr=1.0,\\n            use_gt_bbox=True,\\n            image_thr=0.0,\\n            bbox_file=\\n            'pretrained_models/det/COCO_val2017_detections_AP_H_56_person.json'\\n        ),\\n        pipeline=[\\n            dict(type='LoadImageFromFile'),\\n            dict(type='RandomFlip', flip_prob=0.5),\\n            dict(\\n                type='HalfBodyTransform',\\n                num_joints_half_body=8,\\n                prob_half_body=0.3),\\n            dict(type='RandomScaleRotation', rot_factor=40, scale_factor=0.5),\\n            dict(type='AffineTransform'),\\n            dict(type='ToTensor'),\\n            dict(\\n                type='NormalizeTensor',\\n                mean=[0.485, 0.456, 0.406],\\n                std=[0.229, 0.224, 0.225]),\\n            dict(type='GenerateTarget', sigma=2),\\n            dict(\\n                type='Collect',\\n                keys=['img', 'target', 'target_weight'],\\n                meta_keys=[\\n                    'image_file', 'joints_3d', 'joints_3d_visible', 'center',\\n                    'scale', 'rotation', 'bbox_score', 'flip_pairs'\\n                ])\\n        ]),\\n    val=dict(\\n        type='TopDownCocoDataset',\\n        ann_file='data/coco/annotations/person_keypoints_val2017.json',\\n        img_prefix='data/coco/val2017/',\\n        data_cfg=dict(\\n            image_size=[192, 256],\\n            heatmap_size=[48, 64],\\n            num_output_channels=17,\\n            num_joints=17,\\n            dataset_channel=[[\\n                0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n            ]],\\n            inference_channel=[\\n                0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n            ],\\n            soft_nms=False,\\n            nms_thr=1.0,\\n            oks_thr=0.9,\\n            vis_thr=0.2,\\n            bbox_thr=1.0,\\n            use_gt_bbox=True,\\n            image_thr=0.0,\\n            bbox_file=\\n            'pretrained_models/det/COCO_val2017_detections_AP_H_56_person.json'\\n        ),\\n        pipeline=[\\n            dict(type='LoadImageFromFile'),\\n            dict(type='AffineTransform'),\\n            dict(type='ToTensor'),\\n            dict(\\n                type='NormalizeTensor',\\n                mean=[0.485, 0.456, 0.406],\\n                std=[0.229, 0.224, 0.225]),\\n            dict(\\n                type='Collect',\\n                keys=['img'],\\n                meta_keys=[\\n                    'image_file', 'center', 'scale', 'rotation', 'bbox_score',\\n                    'flip_pairs'\\n                ])\\n        ]),\\n    test=dict(\\n        type='TopDownCocoDataset',\\n        ann_file='data/coco/annotations/person_keypoints_val2017.json',\\n        img_prefix='data/coco/val2017/',\\n        data_cfg=dict(\\n            image_size=[192, 256],\\n            heatmap_size=[48, 64],\\n            num_output_channels=17,\\n            num_joints=17,\\n            dataset_channel=[[\\n                0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n            ]],\\n            inference_channel=[\\n                0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\\n            ],\\n            soft_nms=False,\\n            nms_thr=1.0,\\n            oks_thr=0.9,\\n            vis_thr=0.2,\\n            bbox_thr=1.0,\\n            use_gt_bbox=True,\\n            image_thr=0.0,\\n            bbox_file=\\n            'pretrained_models/det/COCO_val2017_detections_AP_H_56_person.json'\\n        ),\\n        pipeline=[\\n            dict(type='LoadImageFromFile'),\\n            dict(type='AffineTransform'),\\n            dict(type='ToTensor'),\\n            dict(\\n                type='NormalizeTensor',\\n                mean=[0.485, 0.456, 0.406],\\n                std=[0.229, 0.224, 0.225]),\\n            dict(\\n                type='Collect',\\n                keys=['img'],\\n                meta_keys=[\\n                    'image_file', 'center', 'scale', 'rotation', 'bbox_score',\\n                    'flip_pairs'\\n                ])\\n        ]))\\nwork_dir = 'work_dirs/res50_coco_256x192/'\\ngpu_ids = range(0, 1)\\nseed = None\\n\",\n",
       " 'epoch': 210,\n",
       " 'iter': 61320,\n",
       " 'mmcv_version': '1.0rc0',\n",
       " 'time': 'Wed Jul  8 17:24:25 2020'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt['meta']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mot-mmtrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4bfa47eb115d085a5fd36886584e2476f8ebafa1f4dedfed6cf2234c0e3adec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
